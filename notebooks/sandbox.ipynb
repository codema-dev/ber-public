{
 "cells": [
  {
   "source": [
    "To run this Notebook:\n",
    "- Register your email address with SEAI at https://ndber.seai.ie/BERResearchTool/Register/Register.aspx\n",
    "- Run all cells by selecting `Runtime > Run All` from the dropdown menu\n",
    "    - Enter your email address\n",
    "    - (Google Colab) Authenticate `Google Drive` by clicking the URL linked below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_address = input(\"Enter your email eddress: \")"
   ]
  },
  {
   "source": [
    "# Mount Google Drive\n",
    "\n",
    "... skip this section if not running in `Google Colab`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import mkdir\n",
    "from os import path\n",
    "\n",
    "save_directory = \"/content/drive/MyDrive/berpublicsearch\"\n",
    "if path.exists(save_directory):\n",
    "    print(f\"Skipping creation of new folder as {save_directory} already exists!\")\n",
    "else:\n",
    "    mkdir(save_directory)"
   ]
  },
  {
   "source": [
    "# If running outside of `Google Colab`\n",
    "\n",
    "... uncomment this section if running this notebook outside of Google Colab"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import getcwd\n",
    "\n",
    "# save_directory = getcwd()"
   ]
  },
  {
   "source": [
    "# Install Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Uninstall some pre-installed dependencies as they clash with the custom `berpublicsearch` package"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y datascience distributed requests tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/codema-dev/berpublicsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download `BERPublicsearch.zip` and convert to parquet \n",
    "\n",
    "`parquet` is used here inplace of the default `txt` format as it is:\n",
    "1. Compressed on disk: 184 MB vs 972 MB\n",
    "2. Siginficantly faster input speeds as it is read column-by-column rather than row-by-row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_berpublicsearch_zip = f\"{save_directory}/BERPublicsearch.zip\"\n",
    "path_to_berpublicsearch_parquet = f\"{save_directory}/BERPublicsearch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from berpublicsearch.flow import flow\n",
    "\n",
    "flow.run(\n",
    "    email_address=email_address,\n",
    "    path_to_berpublicsearch_zip=path_to_berpublicsearch_zip,\n",
    "    path_to_berpublicsearch_parquet=path_to_berpublicsearch_parquet\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with the BER data in this `sandbox` environment\n",
    "\n",
    "Can now query the BER Public search data in this notebook using `dask`.  `dask` uses `pandas` under the hood but has the advantage of scaling to large data. \n",
    "\n",
    "If you are unfamiliar with `pandas` see:\n",
    "- [Getting started](https://pandas.pydata.org/docs/getting_started/index.html#getting-started)\n",
    "- [Community tutorials](https://pandas.pydata.org/docs/getting_started/tutorials.html?highlight=community) ... includes YouTube videos and interactive tutorials\n",
    "\n",
    "If you are familiar with `pandas` but new to `dask` see:\n",
    "- [Dask DataFrame](https://docs.dask.org/en/latest/dataframe.html)\n",
    "- [Community tutorials](https://docs.dask.org/en/latest/educational-resources.html?highlight=communitytutorials#educational-resources) ... includes YouTube videos and interactive tutorials\n",
    "under the hood so if you are familiar with `pandas` using `dask` is straightforward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ber = dd.read_parquet(path_to_berpublicsearch_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ber.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}